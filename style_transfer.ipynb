{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shelly-hsu/A-style-transfer-sevice/blob/main/style_transfer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RWE19D92RQEz"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from __future__ import print_function\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "from scipy.misc import imsave\n",
        "import numpy as np\n",
        "from scipy.optimize import fmin_l_bfgs_b\n",
        "import time\n",
        "import argparse\n",
        "import tensorflow as tf\n",
        "from keras.applications import vgg19\n",
        "from keras import backend as K\n",
        "from keras.preprocessing.image import load_img\n",
        "import cv2\n",
        "from google.colab import files\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "\n",
        "def style_transfer():\n",
        "  output_folder_path = \"/content/drive/MyDrive/output_img\"     //the folder we store genrated image\n",
        "  result_prefix = \"output\"\n",
        "  iterations = 10                         // iteration can be chage if you want the result to more obvious\n",
        "\n",
        "  # 原圖與風格圖佔output比重\n",
        "  content_weight = 0.025\n",
        "  style_weight = 1.0\n",
        "  # 損失總差異預設值\n",
        "  total_variation_weight = 1.0\n",
        "\n",
        "  # output 圖的寬高\n",
        "  width, height = pre_content.size\n",
        "  img_nrows = 400\n",
        "  img_ncols = int(width * img_nrows / height)\n",
        "\n",
        "  # 轉換成 VGG 19 input 格式\n",
        "  def preprocess_image(image):\n",
        "      img = image.resize((img_ncols, img_nrows))\n",
        "      img = img_to_array(img)\n",
        "      img = np.expand_dims(img, axis=0)\n",
        "      img = vgg19.preprocess_input(img)\n",
        "      return img\n",
        "\n",
        "  # 將特徵向量轉換成 image\n",
        "  def deprocess_image(x):\n",
        "      if K.image_data_format() == 'channels_first':\n",
        "          x = x.reshape((3, img_nrows, img_ncols))\n",
        "          x = x.transpose((1, 2, 0))\n",
        "      else:\n",
        "          x = x.reshape((img_nrows, img_ncols, 3))\n",
        "      # 設定RGB顏色的中心點 (Remove zero-center by mean pixel)\n",
        "      x[:, :, 0] += 103.939\n",
        "      x[:, :, 1] += 116.779\n",
        "      x[:, :, 2] += 123.68\n",
        "      # 'BGR'->'RGB'\n",
        "      x = x[:, :, ::-1]\n",
        "      x = np.clip(x, 0, 255).astype('uint8')\n",
        "      return x\n",
        "\n",
        "  # 設定 Keras 變數 base_image = 原圖 向量\n",
        "  base_image = K.variable(preprocess_image(pre_content))\n",
        "  # 設定 Keras 變數 style_reference_image = 風格圖 向量\n",
        "  style_reference_image = K.variable(preprocess_image(pre_style))\n",
        "\n",
        "  # 設定合成圖的起始值\n",
        "  if K.image_data_format() == 'channels_first':\n",
        "      combination_image = K.placeholder((1, 3, img_nrows, img_ncols))\n",
        "  else:\n",
        "      combination_image = K.placeholder((1, img_nrows, img_ncols, 3))\n",
        "\n",
        "  # 合併原圖、風格圖、合成圖 向量\n",
        "  input_tensor = K.concatenate([base_image,style_reference_image,combination_image], axis=0)\n",
        "\n",
        "  # 載入 VGG 19 模型，不包括加在最後3層的卷積層\n",
        "  model = vgg19.VGG19(input_tensor=input_tensor,weights='imagenet', include_top=False)\n",
        "\n",
        "  # get the symbolic outputs of each \"key\" layer (we gave them unique names).\n",
        "  # 讀取 VGG 19 模型的每一層的名稱與output\n",
        "  outputs_dict = dict([(layer.name, layer.output) for layer in model.layers])\n",
        "\n",
        "  # 計算 風格 loss 的 gram matrix\n",
        "  def gram_matrix(x):\n",
        "      if K.image_data_format() == 'channels_first':\n",
        "          features = K.batch_flatten(x)\n",
        "      else:\n",
        "          features = K.batch_flatten(K.permute_dimensions(x, (2, 0, 1)))\n",
        "      gram = K.dot(features, K.transpose(features))\n",
        "      return gram\n",
        "\n",
        "  # 計算 風格 loss \n",
        "  def style_loss(style, combination):\n",
        "      assert K.ndim(style) == 3\n",
        "      assert K.ndim(combination) == 3\n",
        "      S = gram_matrix(style)\n",
        "      C = gram_matrix(combination)\n",
        "      channels = 3\n",
        "      size = img_nrows * img_ncols\n",
        "      return K.sum(K.square(S - C)) / (4. * (channels ** 2) * (size ** 2))\n",
        "\n",
        "  # 計算 content loss \n",
        "  def content_loss(base, combination):\n",
        "      return K.sum(K.square(combination - base))\n",
        "\n",
        "  # the 3rd loss function, total variation loss,\n",
        "  # designed to keep the generated image locally coherent\n",
        "\n",
        "\n",
        "  # 計算 損失總差異(total variation loss)，以利合成圖的連貫性\n",
        "  def total_variation_loss(x):\n",
        "      assert K.ndim(x) == 4\n",
        "      if K.image_data_format() == 'channels_first':\n",
        "          a = K.square(x[:, :, :img_nrows - 1, :img_ncols - 1] - x[:, :, 1:, :img_ncols - 1])\n",
        "          b = K.square(x[:, :, :img_nrows - 1, :img_ncols - 1] - x[:, :, :img_nrows - 1, 1:])\n",
        "      else:\n",
        "          a = K.square(x[:, :img_nrows - 1, :img_ncols - 1, :] - x[:, 1:, :img_ncols - 1, :])\n",
        "          b = K.square(x[:, :img_nrows - 1, :img_ncols - 1, :] - x[:, :img_nrows - 1, 1:, :])\n",
        "      return K.sum(K.pow(a + b, 1.25))\n",
        "\n",
        "  # 彙總上面三項的損失(loss)\n",
        "  loss = K.variable(0.)\n",
        "  layer_features = outputs_dict['block5_conv2']\n",
        "  base_image_features = layer_features[0, :, :, :]\n",
        "  combination_features = layer_features[2, :, :, :]\n",
        "  loss = loss + content_weight * content_loss(base_image_features,combination_features)\n",
        "\n",
        "  feature_layers = ['block1_conv1', 'block2_conv1',\n",
        "                    'block3_conv1', 'block4_conv1',\n",
        "                    'block5_conv1']\n",
        "  for layer_name in feature_layers:\n",
        "      layer_features = outputs_dict[layer_name]\n",
        "      style_reference_features = layer_features[1, :, :, :]\n",
        "      combination_features = layer_features[2, :, :, :]\n",
        "      sl = style_loss(style_reference_features, combination_features)\n",
        "      loss += (style_weight / len(feature_layers)) * sl\n",
        "  loss += total_variation_weight * total_variation_loss(combination_image)\n",
        "\n",
        "  # 計算合成圖的梯度(gradients)\n",
        "  grads = K.gradients(loss, combination_image)\n",
        "\n",
        "  # 建立 Keras function API 模型\n",
        "  outputs = [loss]\n",
        "  if isinstance(grads, (list, tuple)):\n",
        "      outputs += grads\n",
        "  else:\n",
        "      outputs.append(grads)\n",
        "\n",
        "  f_outputs = K.function([combination_image], outputs)\n",
        "\n",
        "\n",
        "  # 依梯度下降法，評估模型\n",
        "  def eval_loss_and_grads(x):\n",
        "      if K.image_data_format() == 'channels_first':\n",
        "          x = x.reshape((1, 3, img_nrows, img_ncols))\n",
        "      else:\n",
        "          x = x.reshape((1, img_nrows, img_ncols, 3))\n",
        "      outs = f_outputs([x])\n",
        "      loss_value = outs[0]\n",
        "      if len(outs[1:]) == 1:\n",
        "          grad_values = outs[1].flatten().astype('float64')\n",
        "      else:\n",
        "          grad_values = np.array(outs[1:]).flatten().astype('float64')\n",
        "      return loss_value, grad_values\n",
        "\n",
        "  # 評估模型類別\n",
        "  # this Evaluator class makes it possible\n",
        "  # to compute loss and gradients in one pass\n",
        "  # while retrieving them via two separate functions,\n",
        "  # \"loss\" and \"grads\". This is done because scipy.optimize\n",
        "  # requires separate functions for loss and gradients,\n",
        "  # but computing them separately would be inefficient.\n",
        "  class Evaluator(object):\n",
        "      def __init__(self):\n",
        "          self.loss_value = None\n",
        "          self.grads_values = None\n",
        "\n",
        "      def loss(self, x):\n",
        "          assert self.loss_value is None\n",
        "          loss_value, grad_values = eval_loss_and_grads(x)\n",
        "          self.loss_value = loss_value\n",
        "          self.grad_values = grad_values\n",
        "          return self.loss_value\n",
        "\n",
        "      def grads(self, x):\n",
        "          assert self.loss_value is not None\n",
        "          grad_values = np.copy(self.grad_values)\n",
        "          self.loss_value = None\n",
        "          self.grad_values = None\n",
        "          return grad_values\n",
        "\n",
        "  # 執行模型評估\n",
        "  evaluator = Evaluator()\n",
        "\n",
        "  # run scipy-based optimization (L-BFGS) over the pixels of the generated image\n",
        "  # so as to minimize the neural style loss\n",
        "  x = preprocess_image(pre_content)\n",
        "\n",
        "  # 在每一週期產生合成圖\n",
        "  for i in range(iterations):\n",
        "      print('Start of iteration', i)\n",
        "      start_time = time.time()\n",
        "      x, min_val, info = fmin_l_bfgs_b(evaluator.loss, x.flatten(), fprime=evaluator.grads, maxfun=20)\n",
        "      print('Current loss value:', min_val)\n",
        "      # 儲存每一週期的output合成圖\n",
        "      img = deprocess_image(x.copy())\n",
        "      fname = result_prefix + '_at_iteration_%d.png' % i\n",
        "      print(\"store\")\n",
        "      cv2.imwrite(os.path.join(output_folder_path , fname), img)\n",
        "      end_time = time.time()\n",
        "      print('Image saved as', fname)\n",
        "      print('Iteration %d completed in %ds' % (i, end_time - start_time))\n",
        "    \n",
        "      "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "V_fk2JKLJ3IT",
        "outputId": "f73e6dd5-8973-418f-8910-c73249dcdbc5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start of iteration 0\n",
            "Current loss value: 20975272000.0\n",
            "store\n",
            "Image saved as output_at_iteration_0.png\n",
            "Iteration 0 completed in 13s\n",
            "Start of iteration 1\n",
            "Current loss value: 11533148000.0\n",
            "store\n",
            "Image saved as output_at_iteration_1.png\n",
            "Iteration 1 completed in 12s\n",
            "Start of iteration 2\n",
            "Current loss value: 8613443000.0\n",
            "store\n",
            "Image saved as output_at_iteration_2.png\n",
            "Iteration 2 completed in 12s\n",
            "Start of iteration 3\n",
            "Current loss value: 7131065300.0\n",
            "store\n",
            "Image saved as output_at_iteration_3.png\n",
            "Iteration 3 completed in 12s\n",
            "Start of iteration 4\n",
            "Current loss value: 6259508700.0\n",
            "store\n",
            "Image saved as output_at_iteration_4.png\n",
            "Iteration 4 completed in 12s\n",
            "Start of iteration 5\n",
            "Current loss value: 5660512000.0\n",
            "store\n",
            "Image saved as output_at_iteration_5.png\n",
            "Iteration 5 completed in 12s\n",
            "Start of iteration 6\n",
            "Current loss value: 5254630400.0\n",
            "store\n",
            "Image saved as output_at_iteration_6.png\n",
            "Iteration 6 completed in 12s\n",
            "Start of iteration 7\n",
            "Current loss value: 4983628000.0\n",
            "store\n",
            "Image saved as output_at_iteration_7.png\n",
            "Iteration 7 completed in 12s\n",
            "Start of iteration 8\n",
            "Current loss value: 4769187000.0\n",
            "store\n",
            "Image saved as output_at_iteration_8.png\n",
            "Iteration 8 completed in 12s\n",
            "Start of iteration 9\n",
            "Current loss value: 4573714000.0\n",
            "store\n",
            "Image saved as output_at_iteration_9.png\n",
            "Iteration 9 completed in 12s\n",
            "finish\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-29d68978b195>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"finish\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0manvil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_forever\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/anvil/server.py\u001b[0m in \u001b[0;36mwait_forever\u001b[0;34m()\u001b[0m\n\u001b[1;32m    430\u001b[0m     \u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import io\n",
        "import anvil.server\n",
        "import anvil.media\n",
        "from google.colab.patches import cv2_imshow\n",
        "from anvil import URLMedia\n",
        "from anvil.google.drive import app_files\n",
        "\n",
        "\n",
        "anvil.server.connect(\"DISTCQZ2DFDQ5D4HJJFCU7PU-2YNRRVOF3GPXB4K2\")\n",
        "output_folder_path = \"/content/drive/MyDrive/output_img\"\n",
        "@anvil.server.callable\n",
        "def get_input_img(file):\n",
        "  global pre_content\n",
        "  with anvil.media.TempFile(file) as f:\n",
        "    pre_content = load_img(f)\n",
        "@anvil.server.callable\n",
        "def get_style_img(file):\n",
        "  global pre_style\n",
        "  with anvil.media.TempFile(file) as f:\n",
        "    pre_style = load_img(f)\n",
        "\n",
        "@anvil.server.callable\n",
        "def getimage():\n",
        "  img = load_img(\"/content/drive/MyDrive/output_img/output_at_iteration_9.png\")\n",
        "  img_byte_arr = io.BytesIO()\n",
        "  img.save(img_byte_arr, format='JPEG')\n",
        "  img_byte_arr = img_byte_arr.getvalue()\n",
        "  media_obj = anvil.BlobMedia(content_type=\"image/jpeg\", content=img_byte_arr)\n",
        "  return media_obj\n",
        "  \n",
        "@anvil.server.callable\n",
        "def start_style_transfer():\n",
        "  style_transfer()\n",
        "  print(\"finish\")\n",
        "  \n",
        "anvil.server.wait_forever()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVQ4vQsFpxGm",
        "outputId": "ace5ea2b-9fb7-40b7-850f-e5daa2a84a0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iJ-YANzGrnnN"
      },
      "outputs": [],
      "source": [
        "pip install pymysql"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gSTm98XoSDLz",
        "outputId": "3e3a36fc-e83a-4e61-b684-05bb55be307d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scipy==1.2.0\n",
            "  Downloading scipy-1.2.0-cp37-cp37m-manylinux1_x86_64.whl (26.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 26.6 MB 46.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.7/dist-packages (from scipy==1.2.0) (1.19.5)\n",
            "Installing collected packages: scipy\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "jax 0.2.25 requires scipy>=1.2.1, but you have scipy 1.2.0 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed scipy-1.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip install -U scipy==1.2.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFrX88L6Olki"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "QJAaqX_BGRnO",
        "outputId": "c57eb2f7-cee6-4fad-c2cd-1078fe43a657"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting anvil-uplink\n",
            "  Downloading anvil_uplink-0.3.41-py2.py3-none-any.whl (64 kB)\n",
            "\u001b[?25l\r\u001b[K     |█████                           | 10 kB 26.7 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 20 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 30 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 40 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 51 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 61 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 64 kB 2.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from anvil-uplink) (0.16.0)\n",
            "Collecting ws4py\n",
            "  Downloading ws4py-0.5.1.tar.gz (51 kB)\n",
            "\u001b[?25l\r\u001b[K     |██████▍                         | 10 kB 47.7 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 20 kB 52.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 30 kB 54.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 40 kB 55.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 51 kB 55.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51 kB 217 kB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from anvil-uplink) (1.15.0)\n",
            "Collecting argparse\n",
            "  Downloading argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n",
            "Building wheels for collected packages: ws4py\n",
            "  Building wheel for ws4py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ws4py: filename=ws4py-0.5.1-py3-none-any.whl size=45229 sha256=04640e70995950367e11d803ebcde56e10e4eb90f2b0940f7fee44602075fa61\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/ea/7d/3410aa0aa0e4402ead9a7a97ab2214804887e0f5c2b76f0c96\n",
            "Successfully built ws4py\n",
            "Installing collected packages: ws4py, argparse, anvil-uplink\n",
            "Successfully installed anvil-uplink-0.3.41 argparse-1.4.0 ws4py-0.5.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "argparse",
                  "google"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install anvil-uplink"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "style_transfer.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}